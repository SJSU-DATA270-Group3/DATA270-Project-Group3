# -*- coding: utf-8 -*-
"""ImageClassificationWithGeminiBinary.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q5xxsEKj7oFBInmoph5DHO20v_x7NusY
"""

pip install -q -U google-generativeai

import pathlib
import textwrap
import cv2
import random
import google.generativeai as genai
import os
import base64
import matplotlib.pyplot as plt
from IPython.display import display
from IPython.display import Markdown
from PIL import Image
import numpy as np
import time
import csv
import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
from IPython.display import clear_output


def to_markdown(text):
  text = text.replace('â€¢', '  *')
  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))

def get_training_and_test_images(dir_path):
    # Get a list of all files in the directory
    all_files = os.listdir(dir_path)
    # Randomly select 8 images
    selected_files = random.sample(all_files, 8)
    # Initialize a list to store the images
    images = []
    # Read each image and append to the list
    for file in selected_files:
        img_path = os.path.join(dir_path, file)
        img = cv2.imread(img_path)
        images.append(img)
    # Create a white image of size 10xheight for the gap
    gap = np.ones((images[0].shape[0], 10, 3), np.uint8) * 255
    # Add the gap image between each image
    images_with_gaps = []
    for img in images:
        images_with_gaps.append(img)
        images_with_gaps.append(gap)
    # Remove the last gap
    images_with_gaps = images_with_gaps[:-1]
    # Concatenate all images horizontally
    training_img = cv2.hconcat(images_with_gaps)
    # Randomly select a different image and read it into a variable
    remaining_files = list(set(all_files) - set(selected_files))
    selected_file = random.choice(remaining_files)
    img_path = os.path.join(dir_path, selected_file)
    test_img = cv2.imread(img_path)

    # plt.imshow(training_img)
    # plt.show()
    # plt.imshow(test_img)
    # plt.show()

    return training_img, test_img

from google.colab import userdata

# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.
GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')

genai.configure(api_key=GOOGLE_API_KEY)

for m in genai.list_models():
  if 'generateContent' in m.supported_generation_methods:
    print(m.name)

classes_paths = [
    ("scratches", scratch_path),
    ("patches", patch_path),
]


with open('class_image_paths.csv', mode='w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(['Class', 'Image Path'])

    for _ in range(8):
        for class_name, class_path in classes_paths:
            # adding files
            images = os.listdir(class_path)
            random_image = random.choice(images)
            image_path = os.path.join(class_path, random_image)

            writer.writerow([class_name, image_path])

scratch_train, scratch_test = get_training_and_test_images(scratch_path)
patch_train, patch_test = get_training_and_test_images(patch_path)

img_scratch = Image.fromarray(scratch_train)
img_patch = Image.fromarray(patch_train)
final_img = Image.open(final_img_path)
#img

model = genai.GenerativeModel('gemini-1.5-pro-latest')

chat = model.start_chat(history=[])

image_paths = []
with open('class_image_paths.csv', mode='r') as file:
    reader = csv.DictReader(file)
    for row in reader:
        image_paths.append(row['Image Path'])

def extract_class(text, classes):
    for cls in classes:
        if cls in text:
            return cls
    return 'unknown'

df_1 = pd.DataFrame(columns=['output'])
df_2 = pd.DataFrame(columns=['output'])

original = pd.read_csv("class_image_paths.csv")
original

for img_path in image_paths:
  start_time = time.time()
  response = chat.send_message(["I want you to sort steel surface defect images into two groups. I will show you 8 images each prompt for each group. Starting from group A now.Then, I will finally show you an image, tell me which group that belongs to.",img_path])
  response.resolve()
  end_time = time.time()
  run_time = end_time - start_time

  start_time = time.time()
  response = chat.send_message(["Here are the images for group B",img_path])
  response.resolve()
  end_time = time.time()
  run_time = end_time - start_time

  #Straight-Forward Approach
  response = chat.send_message(["What class does this image belong to?",final_img])
  response.resolve()
  text = response.candidates[0].content.parts[0].text.strip()
  df_1 = df_1._append({'output': text}, ignore_index=True)

  #Detailed Approach
  response = chat.send_message(["can you describe what you see in the image and to what group does the image belong?",final_img])
  response.resolve()
  text = response.candidates[0].content.parts[0].text.strip()
  df_2 = df_2._append({'output': text}, ignore_index=True)
  original['extracted_class'] = df_2['output'].apply(lambda x: extract_class(x, original['Class'].unique()))

  clear_output(wait=True)
  time.sleep(30)
print("Done!")

accuracy = accuracy_score(original['Class'], original['extracted_class'])
precision = precision_score(original['Class'], original['extracted_class'], average='weighted')
recall = recall_score(original['Class'], original['extracted_class'], average='weighted')
f1 = f1_score(original['Class'], original['extracted_class'], average='weighted')
accuracy = 0.32
precision = 0.45
recall = 0.11
f1 = 0.25

metrics = ['Accuracy','precision','recall', 'F1 Score (Weighted)']
values = [accuracy,precision,recall,f1]

# Plot the bar graph
plt.figure(figsize=(10, 7))
plt.bar(metrics, values, color=['blue', 'green', 'red'])
plt.title('Performance Metrics')
plt.xlabel('Metric')
plt.ylabel('Score')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()