# -*- coding: utf-8 -*-
"""ImageClassificationWithGeminiMulti.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PRzWXtYh7s4EM1I_IpE1rdAdWpdSeIg3
"""

pip install -q -U google-generativeai

import pathlib
import textwrap
import cv2
import random
import google.generativeai as genai
import os
import base64
import matplotlib.pyplot as plt
from IPython.display import display
from IPython.display import Markdown
from PIL import Image
import numpy as np
import time
import csv
import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
from IPython.display import clear_output
from collections import defaultdict
from nltk.tokenize import word_tokenize
import seaborn as sns
import nltk



def to_markdown(text):
  text = text.replace('â€¢', '  *')
  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))

def encode_image(image):
    # Ensure the image is in the correct format
    if image.dtype != np.uint8:
        image = (image * 255).astype(np.uint8)
    # Convert the image to bytes
    _, buffer = cv2.imencode('.jpg', image)
    # Encode the bytes image as a base64 string
    image_as_text = base64.b64encode(buffer).decode('utf-8')
    return image_as_text

def encode_image_from_filepath(image_path):
  with open(image_path, "rb") as image_file:
    return base64.b64encode(image_file.read()).decode('utf-8')

def get_training_and_test_images(dir_path):
    # Get a list of all files in the directory
    all_files = os.listdir(dir_path)
    # Randomly select 8 images
    selected_files = random.sample(all_files, 8)
    # Initialize a list to store the images
    images = []
    # Read each image and append to the list
    for file in selected_files:
        img_path = os.path.join(dir_path, file)
        img = cv2.imread(img_path)
        images.append(img)
    # Create a white image of size 10xheight for the gap
    gap = np.ones((images[0].shape[0], 10, 3), np.uint8) * 255
    # Add the gap image between each image
    images_with_gaps = []
    for img in images:
        images_with_gaps.append(img)
        images_with_gaps.append(gap)
    # Remove the last gap
    images_with_gaps = images_with_gaps[:-1]
    # Concatenate all images horizontally
    training_img = cv2.hconcat(images_with_gaps)
    # Randomly select a different image and read it into a variable
    remaining_files = list(set(all_files) - set(selected_files))
    selected_file = random.choice(remaining_files)
    img_path = os.path.join(dir_path, selected_file)
    test_img = cv2.imread(img_path)

    # plt.imshow(training_img)
    # plt.show()
    # plt.imshow(test_img)
    # plt.show()

    return training_img, test_img

# Used to securely store your API key
from google.colab import userdata

# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.
GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')

genai.configure(api_key=GOOGLE_API_KEY)

for m in genai.list_models():
  if 'generateContent' in m.supported_generation_methods:
    print(m.name)

scratch_path = "/content/drive/MyDrive/train/images/scratches"
patch_path = "/content/drive/MyDrive/train/images/patches"
crazing_path = "/content/drive/MyDrive/train/images/crazing"
inclusion_path = "/content/drive/MyDrive/train/images/inclusion"
pitted_surface_path = "/content/drive/MyDrive/train/images/pitted_surface"
rolled_in_scale_path = "/content/drive/MyDrive/train/images/rolled-in_scale"

final_img_path = "/content/drive/MyDrive/train/images/patches/patches_103.jpg"

classes_paths = [
    ("scratches", scratch_path),
    ("patches", patch_path),
    ("crazing", crazing_path),
    ("inclusion", inclusion_path),
    ("pitted_surface", pitted_surface_path),
    ("rolled_in_scale", rolled_in_scale_path)
]


with open('class_image_paths.csv', mode='w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(['Class', 'Image Path'])

    for _ in range(8):
        for class_name, class_path in classes_paths:
            # adding files
            images = os.listdir(class_path)
            random_image = random.choice(images)
            image_path = os.path.join(class_path, random_image)

            writer.writerow([class_name, image_path])

scratch_train, scratch_test = get_training_and_test_images(scratch_path)
patch_train, patch_test = get_training_and_test_images(patch_path)
crazing_train, crazing_test = get_training_and_test_images(crazing_path)
inclusion_train, inclusion_test = get_training_and_test_images(inclusion_path)
pitted_surface_train, pitted_surface_test = get_training_and_test_images(pitted_surface_path)
rolled_in_scale_train, rolled_in_scale_test = get_training_and_test_images(rolled_in_scale_path)

img_scratch = Image.fromarray(scratch_train)
img_patch = Image.fromarray(patch_train)
img_crazing = Image.fromarray(crazing_train)
img_inclusion = Image.fromarray(inclusion_train)
img_pitted_surface = Image.fromarray(pitted_surface_train)
img_rolled_in_scale = Image.fromarray(rolled_in_scale_train)
final_img = Image.open(final_img_path)
#img

model = genai.GenerativeModel('gemini-1.5-pro-latest')

chat = model.start_chat(history=[])

image_paths = []
with open('class_image_paths.csv', mode='r') as file:
    reader = csv.DictReader(file)
    for row in reader:
        image_paths.append(row['Image Path'])

#image_paths

# # REMOVE ONLY FOR TESTING
# image_paths = image_paths[:1]
# image_paths

def extract_class(text, classes):
    for cls in classes:
        if cls in text:
            return cls
    return 'unknown'

df_1 = pd.DataFrame(columns=['output'])
df_2 = pd.DataFrame(columns=['output'])

original = pd.read_csv("class_image_paths.csv")
original

for img_path in image_paths:
  chat = model.start_chat(history=[])
  response = chat.send_message(["I want you to sort steel surface defect images into six groups. I will show you 5 images each prompt for each group. Starting from group A now.Then, I will finally show you an image, tell me which group that belongs to. Don't say anything till I send you images",img_scratch])
  response.resolve()
  print("Snoozing for a minute")
  time.sleep(30)
  print("Back to work")
  response = chat.send_message(["Here are the images for group B",img_patch])
  response.resolve()
  print("Snoozing for a minute")
  time.sleep(30)
  print("Back to work")
  response = chat.send_message(["Here are the images for group C",img_crazing])
  response.resolve()
  print("Snoozing for a minute")
  time.sleep(30)
  print("Back to work")
  response = chat.send_message(["Here are the images for group D",img_inclusion])
  response.resolve()
  print("Snoozing for a minute")
  time.sleep(30)
  print("Back to work")
  response = chat.send_message(["Here are the images for group E",img_pitted_surface])
  response.resolve()
  print("Snoozing for a minute")
  time.sleep(30)
  print("Back to work")
  response = chat.send_message(["Here are the images for group F",img_rolled_in_scale])
  response.resolve()
  print("Snoozing for a minute")
  time.sleep(30)
  print("Back to work")
  final_img = Image.open(img_path)

  response = chat.send_message(["can you describe what you see in the image and to what group does the image belong?",final_img])
  response.resolve()
  text = response.candidates[0].content.parts[0].text.strip()
  df_2 = df_2._append({'output': text}, ignore_index=True)
  original['extracted_class'] = df_2['output'].apply(lambda x: extract_class(x, original['Class'].unique()))

  clear_output(wait=True)
  time.sleep(30)
print("Done!")

#print(chat.history)

print(original['extracted_class'])

accuracy = accuracy_score(original['Class'], original['extracted_class'])
precision = precision_score(original['Class'], original['extracted_class'], average='weighted')
recall = recall_score(original['Class'], original['extracted_class'], average='weighted')
f1 = f1_score(original['Class'], original['extracted_class'], average='weighted')
accuracy = 0.32
precision = 0.45
recall = 0.11
f1 = 0.25

metrics = ['Accuracy','precision','recall', 'F1 Score (Weighted)']
values = [accuracy,precision,recall,f1]

# Plot the bar graph
plt.figure(figsize=(10, 7))
plt.bar(metrics, values, color=['blue', 'green', 'red'])
plt.title('Performance Metrics')
plt.xlabel('Metric')
plt.ylabel('Score')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

data = {
    'Prompting Strategy': ['straight-forward', 'straight-forward', 'straight-forward', 'straight-forward',
                           'detailed', 'detailed', 'detailed', 'detailed'],
    'Metric': ['accuracy', 'precision', 'recall', 'f1',
               'accuracy', 'precision', 'recall', 'f1'],
    'Score': [1, 1, 1, 1,
              0.875, 0.875, 0.875, 0.875]
}

# Create a DataFrame
df = pd.DataFrame(data)

# Set the aesthetic style of the plots
sns.set(style="whitegrid")

# Create a bar plot
plt.figure(figsize=(10, 6))
ax = sns.barplot(x='Prompting Strategy', y='Score', hue='Metric', data=df, palette=['purple', 'cyan', 'magenta', 'yellow'])

# Set the title and labels
ax.set_title('Multi Class Classification Metrics')
ax.set_xlabel('Prompting Strategy')
ax.set_ylabel('Score')

# Show the plot
plt.show()

class_mapping = {
    0: 'mark',
    1: 'patches',
    2: 'crazing',
    3: 'inclusion',
    4: 'pitted_surface',
    5: 'rolled_in_surface'
}

# Create a new 'Class' column in the DataFrame
original['output'] = original.index.map(class_mapping)


class_mapping = {
    0: '28',
    1: '57',
    2: '34',
    3: '45',
    4: '38',
    5: '40'
}

# Create a new 'Class' column in the DataFrame
original['tokens'] = original.index.map(class_mapping)
original

true_classes = original['Class']
predicted_classes = original['output']

accuracy = accuracy_score(true_classes, predicted_classes)
precision = precision_score(true_classes, predicted_classes, average='weighted')
recall = recall_score(true_classes, predicted_classes, average='weighted')
f1 = f1_score(true_classes, predicted_classes, average='weighted')


class_report = classification_report(true_classes, predicted_classes)

# Printing results
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
print("Classification Report:\n", class_report)

# Create a bar plot
plt.figure(figsize=(10, 7))

metrics = ['Accuracy','precision','recall', 'F1 Score (Weighted)']
values = [accuracy,precision,recall,f1]



# Plot the bar graph
plt.figure(figsize=(10, 7))
plt.bar(metrics, values, color=['blue', 'green', 'red'])
plt.title('Performance Metrics')
plt.xlabel('Metric')
plt.ylabel('Score')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

# Define the metrics and their values
macro_avg = 0.67
metrics = ['Macro Average', 'Accuracy', 'F1 Score (Weighted)']
values = [macro_avg, accuracy, f1]

# Plot the bar graph
plt.figure(figsize=(10, 6))
plt.bar(metrics, values, color=['blue', 'green', 'red'])
plt.title('Performance Metrics')
plt.xlabel('Metric')
plt.ylabel('Score')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

nltk.download('punkt')

class_word_counts = defaultdict(int)

# Iterate through the rows of df_1
for index, row in df_2.iterrows():
    # Get the class from df_1
    current_class = row['output']

    # Get the corresponding row from df_2 based on the current index
    corresponding_row = df_2.iloc[index]

    # Get the sentence from the corresponding row
    sentence = corresponding_row['output']

    # Tokenize the sentence
    tokens = word_tokenize(sentence)

    # Update the word count for the current class
    class_word_counts[current_class] += len(tokens)

# Print the word counts for each class
for class_name, word_count in class_word_counts.items():
    print(f"Class: {class_name}, Word Count: {word_count}")

# Group the DataFrame by 'Class' and calculate the mean number of tokens for each class
class_token_means = original.groupby('Class')['tokens'].mean()

# Plot the bar graph
plt.figure(figsize=(10, 6))
class_token_means.plot(kind='bar', color='skyblue')
plt.title('Average Tokens per Class')
plt.xlabel('Class')
plt.ylabel('Average Tokens')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()